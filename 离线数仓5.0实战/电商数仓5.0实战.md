## 电商数仓5.0实战

---

### 0 准备服务器

#### 0.1 服务器基本配置

使用vmware创建虚拟机，镜像使用centos7，内存4g，磁盘50g。

启动好虚拟机之后，进行一下配置：

* 修改IP
* 修改hosts
* 修改hostname
* 关闭防火墙

我们一一详细讲述相关操作：

首先是修改IP：

```
虚拟机上网卡只有ens33，因此直接修改这个网卡配置即可。物理机可能会有多个网卡，可以通过ifconfig指令查看网卡以及ip，决定修改哪一个。
vi /etc/sysconfig/network-scripts/ifcfg-ens33

文件内部主要修改两个参数
BOOTPROTO：修改为static，默认为dhcp。由于我们需要固定IP，因此设置为静态
ONBOOT参数是用来指定网络接口是否在系统启动时自动激活的选项。具体来说，当 ONBOOT 参数设置为 yes 时，系统在启动时会自动启用该网络接口；当设置为 no 时，系统启动时不会自动启用该网络接口。

添加参数：
IPADDR：用于配置IP地址，虚拟机的IP地址需要看虚拟网络配置中的网关设置，将末尾的数字改成自己想用的即可
GATEWAY：网关，和虚拟网络配置一致
NETMASK：255.255.255.0
DNS1：随便选一个常用的就行，8.8.8.8是google公共dns服务器
```

剩下三个就在一起说了

```
修改hosts的指令
vi /etc/hosts
映射关系为：IP Hostname

修改hostname的指令
vi /etc/hostname
直接删掉localhost写成自己的就行

关闭防火墙
其中第二个指令是开机也不自启防火墙
systemctl stop firewalld.service
systemctl disable firewalld.service
```

#### 0.2 免密登录、环境变量、用户权限

这两个步骤也都比较简单

免密登录：

```
生成ssh key：
ssh-keygen -t rsa
点三下回车就好了

之后分发秘钥
ssh-copy-id hostname
```

环境变量：

linux的配置文件通常放在/etc目录下，关于环境变量的配置文件放在/etc/profile文件或/etc/profile.d/文件夹。

这里我们在/etc/profile.d/中创建一个专门放我们环境变量的文件my_env.sh。

```
环境变量最终配置给PATH就能在所有位置都能被找到了
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk
export PATH=$PATH:$JAVA_HOME/bin
```

在这之上我们还将脚本文件都放在一个bin目录下(/home/自己的账号/bin中)，并把这个目录配置给Path

```
export PATH=$PATH:/home/自己ID/bin
```

这样我们就可以在全局执行脚本了

用户权限：

在/etc/sudoers中对自己的用户提权

```
## Allow root to run any commands anywhere
root    ALL=(ALL)       ALL

## Allows members of the 'sys' group to run networking, software,
## service management apps and more.
# %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS

## Allows people in group wheel to run all commands
%wheel  ALL=(ALL)       ALL
otaku   ALL=(ALL)       ALL
```



### 1. 环境准备

#### 1.1 Hadoop安装

直接解压压缩包即可，之后配置几个xml

core-site.xml、hdfs-site.xml、mapred.xml和yarn.xml

##### 1.1.1 core-site.xml文件配置

主要需要配置的就是nn的地址和存储目录

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<!-- 指定NameNode的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop102:8020</value>
</property>
<!-- 指定hadoop数据的存储目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop/data</value>
</property>

<!-- 配置HDFS网页登录使用的静态用户为atguigu -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>atguigu</value>
</property>

<!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 -->
    <property>
        <name>hadoop.proxyuser.atguigu.hosts</name>
        <value>*</value>
</property>
<!-- 配置该atguigu(superUser)允许通过代理用户所属组 -->
    <property>
        <name>hadoop.proxyuser.atguigu.groups</name>
        <value>*</value>
</property>
<!-- 配置该atguigu(superUser)允许通过代理的用户-->
    <property>
        <name>hadoop.proxyuser.atguigu.users</name>
        <value>*</value>
</property>
</configuration>
```

##### 1.1.2 hdfs-site.xml文件配置

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<!-- nn web端访问地址-->
	<property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop102:9870</value>
    </property>
    
	<!-- 2nn web端访问地址-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:9868</value>
    </property>
    
    <!-- 测试环境指定HDFS副本的数量1 -->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
</configuration>
```

##### 1.1.3 yarn-site.xml文件配置

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<!-- 指定MR走shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    
    <!-- 指定ResourceManager的地址-->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop103</value>
    </property>
    
    <!-- 环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
    
    <!--yarn单个容器允许分配的最大最小内存 -->
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>4096</value>
    </property>
    
    <!-- yarn容器允许管理的物理内存大小 -->
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>4096</value>
    </property>
    
    <!-- 关闭yarn对物理内存和虚拟内存的限制检查 -->
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
</configuration>
```

##### 1.1.4 mapred-site.xml配置文件

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<!-- 指定MapReduce程序运行在Yarn上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <!-- 历史服务器端地址 -->
	<property>
    	<name>mapreduce.jobhistory.address</name>
    	<value>hadoop102:10020</value>
	</property>

	<!-- 历史服务器web端地址 -->
	<property>
    	<name>mapreduce.jobhistory.webapp.address</name>
    	<value>hadoop102:19888</value>
	</property>
	<!-- 开启日志聚集功能 -->
	<property>
    	<name>yarn.log-aggregation-enable</name>
    	<value>true</value>
	</property>

	<!-- 设置日志聚集服务器地址 -->
	<property>  
    	<name>yarn.log.server.url</name>  
    	<value>http://hadoop102:19888/jobhistory/logs</value>
	</property>

	<!-- 设置日志保留时间为7天 -->
	<property>
    	<name>yarn.log-aggregation.retain-seconds</name>
    	<value>604800</value>
	</property>

</configuration>
```

